{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examlpe Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pymp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5b07c7fa73bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pymp/__init__.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_t, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for process %d...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LOCK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CaptioningModel import *\n",
    "import time\n",
    "import multiprocessing\n",
    "import pymp\n",
    "from joblib import Parallel, delayed\n",
    "import ray\n",
    "\n",
    "model = CaptioningModel()\n",
    "cpus = 2\n",
    "images = 4\n",
    "\n",
    "@ray.remote\n",
    "def ray_predict(model, image_index):\n",
    "    return model.predict(model.train_images[image_index])\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print('Pymp')\n",
    "    \n",
    "    with pymp.Parallel(num_threads=cpus) as p:\n",
    "        start = time.time()\n",
    "        result = [model.predict(model.train_images[i]) for i in p.xrange(images)]\n",
    "        end = time.time()\n",
    "        \n",
    "    print(end - start)\n",
    "    print()\n",
    "    \n",
    "    print('Serial')\n",
    "    \n",
    "    start = time.time()\n",
    "    result = [model.predict(model.train_images[i]) for i in range(images)]\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "    print()\n",
    "    \n",
    "    print('Multiprocessing')\n",
    "    \n",
    "    with multiprocessing.Pool(processes=cpus) as pool:\n",
    "        start = time.time()\n",
    "        result = pool.map(model.predict, model.train_images[:images])\n",
    "        end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "    print()\n",
    "    \n",
    "    print('Joblib')\n",
    "    \n",
    "    start = time.time()\n",
    "    result = Parallel(n_jobs=cpus)(delayed(model.predict)(model.train_images[i]) for i in range(images))\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "    print()\n",
    "    \n",
    "    print('Ray')\n",
    "\n",
    "    ray.init(num_cpus=cpus)\n",
    "    \n",
    "    start = time.time()\n",
    "    result = ray.get([ray_predict.remote(model, i) for i in range(images)])\n",
    "    end = time.time()\n",
    "    \n",
    "    ray.shutdown()\n",
    "    \n",
    "    print(end - start)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CaptioningModel import *\n",
    "import time\n",
    "import multiprocessing\n",
    "import pymp\n",
    "from joblib import Parallel, delayed\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cpus = 2\n",
    "images = 50\n",
    "model = CaptioningModel()\n",
    "cores = [i+1 for i in range(12)]\n",
    "\n",
    "@ray.remote\n",
    "def ray_predict(model, image_index):\n",
    "    return model.predict(model.train_images[image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymp.Parallel(num_threads=cpus) as p:\n",
    "    start = time.time()\n",
    "    result = [model.predict(model.train_images[i]) for i in p.range(images)]\n",
    "    end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.604115962982178\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = [model.predict(model.train_images[i]) for i in range(images)]\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.09216022491455\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    with multiprocessing.Pool(processes=cpus) as pool:\n",
    "        start = time.time()\n",
    "        result = pool.map(model.predict, model.train_images[:images])\n",
    "        end = time.time()\n",
    "    \n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "for item in cores:\n",
    "    cpus = item\n",
    "    \n",
    "    start = time.time()\n",
    "    result = Parallel(n_jobs=cpus)(delayed(model.predict)(model.train_images[i]) for i in range(images))\n",
    "    end = time.time()\n",
    "\n",
    "    times.append(end - start)\n",
    "    print(end - start)\n",
    "    \n",
    "plt.plot(cores, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 12:20:39,946\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=60255)\u001b[0m 2021-04-18 12:20:44.628698: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=60255)\u001b[0m 2021-04-18 12:20:44.628881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=60255)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=60256)\u001b[0m 2021-04-18 12:20:44.628807: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=60256)\u001b[0m 2021-04-18 12:20:44.628964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=60256)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=60255)\u001b[0m 2021-04-18 12:20:46.516791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(pid=60256)\u001b[0m 2021-04-18 12:20:46.516905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.734359979629517\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=cpus)\n",
    "    \n",
    "start = time.time()\n",
    "result = ray.get([ray_predict.remote(model, i) for i in range(images)])\n",
    "end = time.time()\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Backend Code\n",
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir = 'Flickr_Data/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt'\n",
    "test_images_dir = 'Flickr_Data/Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt'\n",
    "images_dir = 'Flickr_Data/Flickr_Data/Images/'\n",
    "model_dir = 'data/model_199.h5'\n",
    "wordtoix_dir = 'data/wordtoix.pkl'\n",
    "ixtoword_dir = 'data/ixtoword.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "train_images = list()\n",
    "doc = load_doc(train_images_dir)\n",
    "\n",
    "for line in doc.split('\\n'):\n",
    "    if len(line) < 1:\n",
    "        continue\n",
    "    \n",
    "    identifier = line.split('.')[0]\n",
    "    train_images.append(images_dir + identifier + '.jpg')\n",
    "\n",
    "print('Dataset: %d' % len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "test_images = list()\n",
    "doc = load_doc(test_images_dir)\n",
    "\n",
    "for line in doc.split('\\n'):\n",
    "    if len(line) < 1:\n",
    "        continue\n",
    "    \n",
    "    identifier = line.split('.')[0]\n",
    "    test_images.append(images_dir + identifier + '.jpg')\n",
    "\n",
    "print('Dataset: %d' % len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = 'Start '\n",
    "end_token = ' End'\n",
    "max_length = 30\n",
    "wordtoix = pickle.load(open(wordtoix_dir, 'rb'))\n",
    "ixtoword = pickle.load(open(ixtoword_dir, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    image = load_img(filename, target_size=(299, 299))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    return np.reshape(feature, (1, feature.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedySearch(photo, model):\n",
    "    in_text = start_token[:-1]\n",
    "    \n",
    "    for i in range(15):\n",
    "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo,sequence])\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = ixtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        \n",
    "        if word == end_token[1:]:\n",
    "            break\n",
    "    \n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = [x[0] for x in groupby(final)]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_dir):\n",
    "    global model\n",
    "    image = preprocess_image(image_dir)\n",
    "    return greedySearch(image, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "కుక్కలతో బీచ్ లో ముగ్గురు కుక్కలతో ఆడుతున్నారు చూస్తున్నారు బంతిని చూస్తున్నారు మరొకటి కుక్క గాలిలో దూకుతోంది\n"
     ]
    }
   ],
   "source": [
    "caption = predict(train_images[2817])\n",
    "print(caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
